{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The Exercise\n",
    "\n",
    "ExampleCo, Inc is gathering several types of data for its fleet of very expensive machines. They collect four kinds of time series data for each machine in their fleet. When a machine is operating in normal mode the data behaves in a fairly predictable way, but with a moderate amount of noise. Before a machine fails it will ramp into faulty mode, during which the data appears visibly quite different. Finally, when a machine fails it enters a third, and distinctly different, failed mode where all signals are very close to zero. There are four common sensors associated with each machine. There is also static data associated with each machine.\n",
    "\n",
    "ExampleCo stores their data in SQL tables. While SQL is useful for storing and querying data, it is less useful as input for machine learning pipelines. At Tagup, our ML Pipelines expect data as an n-dimensional array, and a common first step is converting a customer's data from SQL to array form.\n",
    "\n",
    "You can download the data here: [exampleco_data](https://drive.google.com/file/d/1GejVDBoFFVNprqMeTGnXu8hrYLj4aS4q/view?usp=sharing)\n",
    "\n",
    "Your objectives are:\n",
    "\n",
    "- Map the equipment data from SQL into arrays (or a single array). To keep things simple, you can ignore the static data to start. Be sure to describe your design choices and the array schema you chose.\n",
    "- Apply filters to clean the data. There are some clear outliers in the data due to communication errors from the sensor equipment. A good place to start is to find a way to filter them out.\n",
    "- Explain why your design and approach is effective, in language a non-technical executive can understand. If helpful, use visualizations to demonstrate the efficacy of your approach.\n",
    "\n",
    "Bonus points:\n",
    "- Integrate the static data into your design.\n",
    "- Provide summary statistics for the ingressed data, including various statistical moments, and any other relevant descriptive statistics.\n",
    "- As part of a data processing pipeline, upload your arrays to AWS S3.\n",
    "    \n",
    "A few notes to help:\n",
    "1. Feel free to use any libraries you like. At Tagup, we use [xarray](http://xarray.pydata.org/en/stable/) for multidimensional arrays, but you can use whatever methods you prefer. Your final results should be shared via GitHub, including a README file providing documentation (ideally of both your code and your findings in the data). There is a jupyter notebook included to help you get started, but do not feel obligated to submit your solution in notebook form.\n",
    "    \n",
    "2. There are no constraints on the techniques you bring to bear, we are curious to see how you think and what sort of resources you have in your toolbox.\n",
    "    \n",
    "3. Don't hesitate to reach out to challenges@tagup.io with any questions!\n",
    "    \n",
    "\n",
    "## Tips\n",
    "- We value syntax, structure and variable naming, code documentation, and testability.\n",
    "- Try to design and implement your solution as you would do for real production code. Show us how you create clean and maintainable code that produces the target result. Build something that we'd be happy to contribute to.\n",
    "- Feel free to add more features: we're curious about what you can think of. We'd expect the same if you worked with us!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is some code to help you get started\n",
    "Feel free to modify or remove any of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load db\n",
    "engine = create_engine('sqlite:///exampleco_db.db', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View tables\n",
    "inspector = inspect(engine)\n",
    "inspector.get_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run example query\n",
    "query = \"SELECT * FROM feat_0 LIMIT 20;\"\n",
    "engine.execute(query).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39ee16c09488673965437987a2869652385c44c089bebde15996833fbab8938b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
